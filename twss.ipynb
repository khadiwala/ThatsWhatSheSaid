{
 "metadata": {
  "name": "twss"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's What She Said: Automated Detection of Innuendos\n",
      "======================================================\n",
      "\n",
      "Here a describe my second pass at writing a classifier that can detect sentences that are likely to contain sexual inuendos. Both implementations can be found on [github](https://github.com/mrgrieves/ThatsWhatSheSaid), as well as this notebook. My primary motivation was to familiarize myself with the basics of the very easy to use [scikit-learn](http://scikit-learn.org/stable/) library, as opposed to using the basic classifiers in nltk. I also got substantially better performance and memory usage, and used a cool feature extraction technique that is well suited to bag of words models. Also I learned the wonder that is blogging with ipython notebooks, which is the coolest thing since sliced bread. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Process the Data\n",
      "========================\n",
      "\n",
      "The data folder of the github project contains three sources. Two are of negative instances: one scraped from fmylife and the other from texts from last night. The thought here is that these samples would be written a similar tone and style to twss instances without being twss worthy. The positive samples are scraped from twss. The punctuation has already been processed out, and the data has been slightly cleaned. This [data](http://blog.echen.me/2011/05/05/twss-building-a-thats-what-she-said-classifier/) (also availiable in my repo) was scraped by Edwin Chen, and the approach seems to be from this [paper](http://www.aclweb.org/anthology-new/P/P11/P11-2016.pdf)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import chain\n",
      "import numpy as np\n",
      "\n",
      "load = lambda x  : open(x).readlines()\n",
      "stopwords = set(open(load(\"english\")))\n",
      "stopwords.add(\"twss\")\n",
      "stopwords.add(\"fml\")\n",
      "pos = load(\"data/twss-stories-parsed.txt\")\n",
      "negs = [\"data/fmylife-parsed.txt\",\"data/texts-from-last-night-parsed.txt\"]\n",
      "neg = list(chain(*map(load,negs)))\n",
      "\n",
      "def tokens(s):\n",
      "    return [word for word in s.rstrip().lower().split() if word not in stopwords]\n",
      "\n",
      "pos_f = map(tokens, pos)\n",
      "neg_f = map(tokens, neg)\n",
      "all_f = chain(pos_f,neg_f)\n",
      "target = np.concatenate([np.ones(len(pos)),np.zeros(len(neg))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Feature Extraction\n",
      "==================\n",
      "\n",
      "Hash Trick\n",
      "----------\n",
      "Here's the more interesting part. This uses the fairly recent FeatureHasher functionality in SciKit-Learn starting with version 0.13.\n",
      "\n",
      "With any text classification that has a decent size corpus, we can expect to see a huge number of features. However, each instance has very few of these features active. The first way to mitigate this effect is to use a [sparse matrix](http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix) as representation of the feature vectors. The additional benefit that the [hash trick](http://scikit-learn.org/stable/modules/feature_extraction.html#feature-hashing) provides is that the hash maps directly to the indicies in the array. This means we don't have to keep an in memory mapping to feature indicies. \n",
      "\n",
      "I had previously implemented this using a more straightforward approach and paid pretty large memory costs, that bottlenecked the entire process. Add to that I had not discovered the beauty of ipython notebooks and their mechanism modularizing code and only running certain cells, and I had a very slow development cycle. That's the implementation in the master branch of my twss repo. \n",
      "\n",
      "Negatives\n",
      "---------\n",
      "You can't go backwords from the hashes to the features, so you lose the ability to easily introspect about the performance of features in the classifier. Because of this, I pulled out some info on the most informative features when I did this experiment with nltk's implementation of naive bayes at the end of this post. Because dirty words are funny. Since this was mostly to try out different models and an interesting feature extraction technique, I did not go through the pain of mapping every single feature to it's index to find which features corresponded to the indicies that were most informative in the classifiers I tried out.\n",
      "\n",
      "Potential collisions grow more likely as you approach the size of the hash space, $2^{31}$, (which I clearly do not with this data set). They are slightly mitigated by using a signed hash that determines the sign of the feature. This means collisions are more likely to cancel out than accumulate bias. It was suggested in [Weinberger et al](http://alex.smola.org/papers/2009/Weinbergeretal09.pdf)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import feature_extraction as fe\n",
      "fh = fe.FeatureHasher(input_type='string')\n",
      "all_h = fh.transform(all_f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Classification\n",
      "==============\n",
      "\n",
      "Benchmarking\n",
      "------------\n",
      "I pulled and modified some code to do the evaluation and timing (as well as the plotting further down), from the very good example from scikit [Classification of Text Documents using Sparse Features](http://scikit-learn.org/0.13/auto_examples/document_classification_20newsgroups.html). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "from time import time\n",
      "\n",
      "\n",
      "def benchmark(clf, X, Y, train, test):\n",
      "    clf_descr = clf[0]\n",
      "    clf = clf[1]\n",
      "    print(80 * '_')\n",
      "    print(\"Training: \")\n",
      "    print(clf)\n",
      "    t0 = time()\n",
      "    clf.fit(X[train], Y[train])\n",
      "    train_time = time() - t0\n",
      "    print(\"train time: %0.3fs\" % train_time)\n",
      "\n",
      "    t0 = time()\n",
      "    pred = clf.predict(X[test])\n",
      "    test_time = time() - t0\n",
      "    print(\"test time:  %0.3fs\" % test_time)\n",
      "\n",
      "    score = metrics.f1_score(Y[test], pred)\n",
      "    print(\"f1-score:   %0.3f\" % score)\n",
      "\n",
      "    print(\"confusion matrix:\")\n",
      "    print(metrics.confusion_matrix(Y[test], pred))\n",
      "\n",
      "    print()\n",
      "    return clf_descr, score, train_time, test_time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Models\n",
      "------\n",
      "\n",
      "Scikit-learn is so well designed that swapping models in and out is too easy not to try. I looked for pretty much anything I could apply to a sparse matrix with negative entities. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import Perceptron, PassiveAggressiveClassifier, RidgeClassifier\n",
      "from sklearn import cross_validation\n",
      "from sklearn.naive_bayes import BernoulliNB\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.neighbors import NearestCentroid\n",
      "\n",
      "cv = cross_validation.KFold(all_h.shape[0], n_folds=5, shuffle=True)\n",
      "train,test = next(iter(cv)) # just use one of the folds\n",
      "\n",
      "clss = [\n",
      "        (\"Perceptron\", Perceptron(n_iter=50,n_jobs=2)),\n",
      "        (\"BernoulliNB\", BernoulliNB()),\n",
      "        (\"Ridge\", RidgeClassifier(tol=1e-2, solver=\"lsqr\")),\n",
      "        (\"NearestCentroid\", NearestCentroid()),\n",
      "        (\"LinearSVC l1\", LinearSVC(loss='l2', penalty=\"l1\", dual=False, tol=1e-3)),\n",
      "        (\"LinearSVC l2\", LinearSVC(loss='l2', penalty=\"l2\", dual=False, tol=1e-3)),\n",
      "        (\"SGD l1\", SGDClassifier(alpha=.0001, n_iter=50, penalty=\"l1\")),\n",
      "        (\"SGD l2\", SGDClassifier(alpha=.0001, n_iter=50, penalty=\"l2\")),\n",
      "        (\"SGD elasticnet\", SGDClassifier(alpha=.0001, n_iter=50, penalty=\"elasticnet\"))\n",
      "       ]\n",
      "results = [benchmark(cls,all_h,target,train,test) for cls in clss]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "________________________________________________________________________________\n",
        "Training: \n",
        "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
        "      n_iter=50, n_jobs=2, penalty=None, random_state=0, shuffle=False,\n",
        "      verbose=0, warm_start=False)\n",
        "train time: 0.496s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.009s\n",
        "f1-score:   0.863\n",
        "confusion matrix:\n",
        "[[1080   53]\n",
        " [  67  377]]\n",
        "\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "train time: 0.100s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.163s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "f1-score:   0.000\n",
        "confusion matrix:\n",
        "[[1133    0]\n",
        " [ 444    0]]\n",
        "\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
        "        max_iter=None, normalize=False, solver=lsqr, tol=0.01)\n",
        "train time: 50.880s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.008s\n",
        "f1-score:   0.866\n",
        "confusion matrix:\n",
        "[[1098   35]\n",
        " [  78  366]]\n",
        "\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "NearestCentroid(metric=euclidean, shrink_threshold=None)\n",
        "train time: 0.037s\n",
        "test time:  0.036s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "f1-score:   0.694\n",
        "confusion matrix:\n",
        "[[995 138]\n",
        " [135 309]]\n",
        "\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "     intercept_scaling=1, loss=l2, multi_class=ovr, penalty=l1,\n",
        "     random_state=None, tol=0.001, verbose=0)\n",
        "train time: 0.719s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.006s\n",
        "f1-score:   0.887\n",
        "confusion matrix:\n",
        "[[1099   34]\n",
        " [  63  381]]\n",
        "\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "     intercept_scaling=1, loss=l2, multi_class=ovr, penalty=l2,\n",
        "     random_state=None, tol=0.001, verbose=0)\n",
        "train time: 3.872s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.006s\n",
        "f1-score:   0.877\n",
        "confusion matrix:\n",
        "[[1087   46]\n",
        " [  61  383]]\n",
        "\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate=optimal,\n",
        "       loss=hinge, n_iter=50, n_jobs=1, penalty=l1, power_t=0.5,\n",
        "       random_state=None, rho=None, shuffle=False, verbose=0,\n",
        "       warm_start=False)\n",
        "train time: 0.618s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.006s\n",
        "f1-score:   0.874\n",
        "confusion matrix:\n",
        "[[1087   46]\n",
        " [  64  380]]\n",
        "\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate=optimal,\n",
        "       loss=hinge, n_iter=50, n_jobs=1, penalty=l2, power_t=0.5,\n",
        "       random_state=None, rho=None, shuffle=False, verbose=0,\n",
        "       warm_start=False)\n",
        "train time: 0.583s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.006s\n",
        "f1-score:   0.867\n",
        "confusion matrix:\n",
        "[[1087   46]\n",
        " [  69  375]]\n",
        "\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate=optimal,\n",
        "       loss=hinge, n_iter=50, n_jobs=1, penalty=elasticnet, power_t=0.5,\n",
        "       random_state=None, rho=None, shuffle=False, verbose=0,\n",
        "       warm_start=False)\n",
        "train time: 0.611s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.006s\n",
        "f1-score:   0.873\n",
        "confusion matrix:\n",
        "[[1098   35]\n",
        " [  73  371]]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pylab as pl\n",
      "\n",
      "indices = np.arange(len(results))\n",
      "\n",
      "collected = [[x[i] for x in results] for i in range(4)]\n",
      "\n",
      "clf_names, score, training_time, test_time = collected\n",
      "training_time = np.array(training_time) / np.max(training_time)\n",
      "test_time = np.array(test_time) / np.max(test_time)\n",
      "\n",
      "pl.title(\"Score\")\n",
      "pl.barh(indices, score, .2, label=\"score\", color='r')\n",
      "pl.barh(indices + .3, training_time, .2, label=\"training time\", color='g')\n",
      "pl.barh(indices + .6, test_time, .2, label=\"test time\", color='b')\n",
      "pl.yticks(())\n",
      "pl.legend(loc='lower left', bbox_to_anchor=(1,.5))\n",
      "pl.subplots_adjust(left=.25)\n",
      "\n",
      "for i, c in zip(indices, clf_names):\n",
      "    pl.text(-.3, i, c)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAEHCAYAAABGGYSOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n"
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's What She Said!\n",
      "=====================\n",
      "Great! Most of the models had similar performance, but on this data set it looks like LinearSVC performed well. Let's use this classifier to make crude jokes!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def to_sentences(document):\n",
      "    text = \"\"\n",
      "    for line in load(document):\n",
      "        text += line\n",
      "    return text.lower().split('.')\n",
      "\n",
      "clf = LinearSVC(loss='l2', penalty=\"l1\", dual=False, tol=1e-3)\n",
      "clf.fit(all_h,target)\n",
      "\n",
      "def get_twss(fn):\n",
      "    sentences = to_sentences(fn)\n",
      "    hashed = fh.transform(map(tokens,sentences))\n",
      "    twss_pairs = filter(lambda x : x[1] == 1, zip(sentences,clf.predict(hashed)))\n",
      "    return map(lambda x : x[0], twss_pairs)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "State of the Union\n",
      "------------------\n",
      "\n",
      "First let's try Obama's 2013 State of the Union. Shouldn't expect too much from here, as most of these sentences will probably be non personal and contain policy related language. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for s in get_twss(\"data/2013-state-of-union.txt\"):\n",
      "    print(s.strip())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "but we gather here knowing that there are millions of americans whose hard work and dedication have not yet been rewarded\n",
        "it is our unfinished task to restore the basic bargain that built this country \u2013 the idea that if you work hard and meet your responsibilities, you can get ahead, no matter where you come from, what you look like, or who you love\n",
        "now, some in this congress have proposed preventing only the defense cuts by making even bigger cuts to things like education and job training; medicare and social security benefits\n",
        "our government shouldn\u2019t make promises we cannot keep \u2013 but we must keep the promises we\u2019ve already made\n",
        "the politics will be hard for both sides\n",
        "it\u2019s not a bigger government we need, but a smarter government that sets priorities and invests in broad-based growth\n",
        "there are things we can do, right now, to accelerate this trend\n",
        "we produce more natural gas than ever before \u2013 and nearly everyone\u2019s energy bill is lower because of it\n",
        "solar energy gets cheaper by the year \u2013 so let\u2019s drive costs down even further\n",
        "as long as countries like china keep going all-in on clean energy, so must we\n",
        "if a non-partisan coalition of ceos and retired generals and admirals can get behind this idea, then so can we\n",
        "and i know that you want these job-creating projects in your districts\n",
        "now, even with better high schools, most young people will need some higher education\n",
        "tonight, let\u2019s also recognize that there are communities in this country where no matter how hard you work, it\u2019s virtually impossible to get ahead\n",
        "let\u2019s offer incentives to companies that hire americans who\u2019ve got what it takes to fill that job opening, but have been out of work so long that no one will give them a chance\n",
        "i recognize that in our democracy, no one should just take my word that we\u2019re doing things the right way\n",
        "overwhelming majorities of americans \u2013 americans who believe in the 2nd amendment \u2013 have come together around commonsense reform \u2013 like background checks that will make it harder for criminals to get their hands on a gun\n",
        "police chiefs are asking our help to get weapons of war and massive ammunition magazines off our streets, because they are tired of being outgunned\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hah! most of these are bad and it's not hard to see why they were misclassified, a lot of use of comparitive adjectives like bigger, harder further, etc. There are a couple good ones though, I enjoyed:\n",
      "\n",
      "* the politics will be hard for both sides\n",
      "\n",
      "* we produce more natural gas than ever before \u2013 and nearly everyone\u2019s energy bill is lower because of it\n",
      "\n",
      "* there are things we can do, right now, to accelerate this trend\n",
      "\n",
      "Let's see if there is anything better in George Bush's 2002 state of the union. If I remember correctly we could broach some sensitive topics, hot dog!\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for s in get_twss(\"data/2002-state-of-union.txt\"):\n",
      "    print(s.strip())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "when i called our troops into action, i did so with complete confidence in their courage and skill\n",
        "i don't want to play football until i can play with you again some day\n",
        "so long as training camps operate, so long as nations harbor terrorists, freedom is at risk\n",
        "our war on terror is well begun, but it is only begun\n",
        "this campaign may not be finished on our watch \u2014 yet it must be and it will be waged on our watch\n",
        "we can't stop short\n",
        "last year, some in this hall thought my tax relief plan was too small; some thought it was too big\n",
        "employees who have worked hard and saved all their lives should not have to risk losing everything if their company fails\n",
        "for too long our culture has said, \"if it feels good, do it\n",
        "we've come to know truths that we will never question: evil is real, and it must be opposed\n",
        "deep in the american character, there is honor, and it is stronger than cynicism\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bahaha! Amazing! Almost all of these are perfect twss candidates, or so far from it that it's wonderful. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And with that, all possible remnants of humor left in the That's What She Said jokes have been taken out to the shed and shot."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}